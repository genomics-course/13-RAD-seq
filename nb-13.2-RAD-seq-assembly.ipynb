{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 13.2: RAD-seq assembly\n",
    "\n",
    "### Learning objectives: \n",
    "\n",
    "By the end of this notebook you will:\n",
    "\n",
    "1. Learn to use the ipyrad software for RAD-seq assembly.\n",
    "2. Be able to describe the difference between denovo and reference assemblies.\n",
    "3. Be familiar with output RAD-seq files for downstream analyses. \n",
    "\n",
    "\n",
    "### Assigned readings:\n",
    "\n",
    "1. Andrews, Kimberly R., Jeffrey M. Good, Michael R. Miller, Gordon Luikart, and Paul A. Hohenlohe. 2016. “Harnessing the Power of RADseq for Ecological and Evolutionary Genomics.” Nature Reviews Genetics 17 (2): 81. https://doi.org/10.1038/nrg.2015.28.\n",
    "\n",
    "\n",
    "\n",
    "2. Eaton, Deren A. R., Andrew L. Hipp, Antonio González-Rodríguez, and Jeannine Cavender-Bares. 2015. “Historical Introgression among the American Live Oaks and the Comparative Nature of Tests for Introgression.” Evolution 69 (10): 2587–2601. https://doi.org/10.1111/evo.12758.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "import toyplot\n",
    "import toytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling RAD-seq data sets\n",
    "In the last notebook you examined some RAD-seq data in fastq format. The goal of RAD-seq assembly is to take all of these short-read sequences from across the genome and to accurately construct orthologous loci across samples. This can be done in one of two ways: (1) by mapping to a reference genome; or (2) by clustering *de novo* based on sequence similarity. These approaches each have different advantages particularly when working across different evolutionary scales and in systems with or without a well assembled reference genome. \n",
    "\n",
    "The final results of an assembly of RAD-seq data can be *variant calls*, in which case you are interested in finding SNPs that vary among the individuals in your data set; or it can include assembled loci, in which case the results are loci constructed from the overlapping reads adjacent to each restriction recognition site in the genome. The latter is particularly useful for phylogenetics or some population genetic inference methods that require information about variant sites as well as invariants sites in the genome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard pipelines (reference map)\n",
    "\n",
    "The methods we've used previously for mapping shotgun sequence data to a reference genome (e.g., bwa) can similarly be used to map RAD-seq data to a reference. Afterall, RAD-seq is just Illumina short-read data that covers a subset of the genome. We'll cover variant calling methods for whole genome sequence data in the coming week. There are many options and ways to do this and it usually involves combining many different software tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialized pipelines (denovo or reference map)\n",
    "A simpler approach that can be appealing is to use an assembly pipeline that is able to accomplish all of the tasks involved in assembly within a single program call. For example, this would include read mapping, filtering, variant calling, and formatting output files for various downstream analyses, or providing the analysis functions built-in. A number of tools have been developed for this purpose that specialize in RAD-seq data. These tools usually offer methods for both reference-mapped assembly and *de novo* assembly of RAD-seq data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipyrad toolkit \n",
    "\n",
    "Here we'll use the program `ipyrad` for assembling and analyzing RAD-seq data sets. This is a tool written in Python that is designed to integrate well with Jupyter Notebooks for creating reproducible workflows. Feel free to explore the [ipyrad documentation](https://ipyrad.readthedocs.io) for details. In a similar manner to the `canu` software we learned about recently, `ipyrad` aims to be an all-in-one pipeline for assembling RAD-seq data starting from the raw sequence data to the final assembled data files. It can be called as a command line tool from a terminal, or be used within Python as a object-oriented package. We'll use the Python API version. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipyrad Python API\n",
    "The ipyrad API is centered around an object called an `Assembly`. This stores the parameters that you can set and which tell the program how to run, and it has functions that can be called to execute the assembly of the data. Below we start an assembly by creating a new Assembly object and providing it a name (\"test\"). The `.params` attribute returns a printed view of the parameter options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an named object to represent the Assembly of the data\n",
    "data = ip.Assembly(\"test\")\n",
    "\n",
    "# print all of the parameters options for this assembly\n",
    "data.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "As described in the documentation there is a large number of parameters that can be modified, but few that are required to be set. Here we will set the required parameters but leave most of the other optional parameters at their default settings. We enter the path to the data files and tell `ipyrad` to perform a reference-based assembly. We also set the parameter `project_dir` to the name \"simdata\". This will create a new folder in our current directory called \"simdata\" and organize all of the files produced by the assembly into that folder. \n",
    "Finally we print the parameters again which you can see have been updated from before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the values for several parameters\n",
    "data.params.project_dir = \"~/work/simdata\"\n",
    "data.params.raw_fastq_path = \"/home/jovyan/ro-data/ipsimdata/rad_example_R1_.fastq.gz\"\n",
    "data.params.barcodes_path = \"/home/jovyan/ro-data/ipsimdata/rad_example_barcodes.txt\"\n",
    "data.params.reference_sequence = \"/home/jovyan/ro-data/ipsimdata/rad_example_genome.fa\"\n",
    "data.params.assembly_method = \"reference\"\n",
    "\n",
    "# print the new parameters\n",
    "data.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast simulated example assembly\n",
    "Once the parameters are set on your assembly object you can use the `.run()` command to run the steps of the assembly process. This will automatically distribute the work in parallel across multiple processors. Below we tell the program to run all seven steps of the assembly. This data set is quite small, only 500 loci across 12 samples. It can complete the assembly using four processors in about a minute. Here you can simply watch the entire assembly run. Next we'll break it down to examine what is happening in each step of the assembly. \n",
    "\n",
    "The assembly process in ipyrad is broken into seven steps, as shown below. This atomized process is useful as you can examine how changing different parameters of the assembly process influences the results. For example you may try one assembly with a set of parameters, and then another that branches from the first assembly at step 5 and uses a different set of parameters for the remaining few steps. We'll see examples of this later. \n",
    "\n",
    "![https://ipyrad.readthedocs.io/_images/steps.png](https://ipyrad.readthedocs.io/_images/steps.png)\n",
    "\n",
    "\n",
    "The `force=True` argument is set here to tell the `.run()` command to overwrite an existing data assembly if one already exists with this name. This is required if you run this cell multiple times, otherwise it will not overwrite the existing assembly the second time you run it. The `auto=True` parameter automatically detects the available processors on the computer you are using and parallelizes the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: run the full assembly in one command\n",
    "data.run(\"1234567\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of the ipyrad assembly\n",
    "\n",
    "### Step 1: demultiplexing/loading reads\n",
    "Step 1 of the assembly has two possible functions. If the data are already demultiplexed then you can provide `ipyrad` with the fastq files for each individual in your data set and it will simply load in and count the number of reads for each sample. If your data are not yet demultiplexed then you must provide the *raw fastq file* with all of your sequence data and a *barcodes file* that maps sample names to their barcode sequences. That is the approach we are using here. We start by demultiplexing the sequences to samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the raw fastq path earlier \n",
    "data.params.raw_fastq_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the barcodes file earlier\n",
    "data.params.barcodes_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook we examined the protocol for preparing a RAD-seq library which included ligating barcodes fragmented genome sequences. This information is one of the required inputs for demultiplexing the raw reads and assigning them to each individual sample. The file above simply lists in tab-delimited form a sample name and barcode sequence on each line. We can access the parsed form of this information as a dictionary as shown below by accessing the `.barcodes` attrbute of the Assembly object. During step 1 ipyrad will use this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the barcode info can be viewed as a dictionary mapping names to barcodes\n",
    "data.barcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are restarting the same assembly that we had previously completed. It has the same assembly name and project_dir. To overwrite the previous assembly we use the force=True flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run step 1 to demultiplex the data\n",
    "data.run(\"1\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the results of step 1 demultiplexing\n",
    "data.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same general framework can be followed for the remaining steps. Run the step, check the stats output, and perhaps modify parameters that affect that step to see how they change the results. The documentation has details on which parameters affect which steps of the assembly. \n",
    "\n",
    "A convenience of being able to access the statistics of the assembly in Python and as a DataFrame is that we can easily calculate further values from the results. For example, if we want to know the total number of reads across all samples we can calculate the sum. Similarly, we could calculate variance, or plot the values, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total reads across all samples\n",
    "data.stats.reads_raw.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filtering reads\n",
    "We've discussed previously the importance of filtering and trimming short reads before using them for a whole genome assembly. This is also true for RAD-seq data sets. Step 2 in ipyrad performs this step. Because we are currently working with a simulated data set there is no adapter contamination and the reads are all high quality. But we will see later in empirical examples that this step can be very important. If we wanted to set a higher stringency for filtering we can increase the `filter_adapters` parameter to a higher value (options are 0, 1, 2, or 3). Further details are in the documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filtering parameter to a more stringent threshold\n",
    "data.params.filter_adapters = 2\n",
    "\n",
    "# continue this assembly from step 1 to step 2\n",
    "data.run(\"2\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the stats summary\n",
    "data.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are also more detailed stats summaries avaiable for each step\n",
    "data.stats_dfs.s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cluster or map reads\n",
    "Depending on whether the `assembly_method` parameter is set to *denovo* or *reference* this step will perform a slightly different task. In denovo mode it uses a clustering algorithm to identify reads within each sample that are sequenced copies from the same locus. If in reference mode then the same thing is accomplished by mapping reads to a reference genome. In either case, we expect that many reads are assigned to each locus in the dataset so that we have high coverage for making accurate base calls later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue this assembly from step 2 to step 3\n",
    "data.run(\"3\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the detailed statistics for step 3 read mapping\n",
    "data.stats_dfs.s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 4-5: Consensus haplotype calling \n",
    "Once reads are mapped to each locus ipyrad then aims to make consensus haplotype calls within each individual. With high coverage data we expect to recover both alleles for diploid organisms and to correct for sequencing errors. Step 4 uses the read coverage information to first jointly estimate the error rate and heterozygosity. Then step 5 uses these values to make base calls and infer haplotypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run steps 4 and 5\n",
    "data.run(\"45\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at summarized stats so far\n",
    "data.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Across sample orthology\n",
    "Up to this point processing has occurred in each sample individually. Now in step 6 we either use clustering again to identify orthology among consensus reads from different individuals in *denovo* assemblies, or we use the reference mapped locations to build loci of orthologous consensus sequences across samples for *reference-based* assemblies. \n",
    "\n",
    "For closely related organisms the reference-based assemblies will usually give the best results, and will run much faster. However, if you do not have a closely related genome to your study clade, or if the organisms in your study span a very wide phylogenetic scale (e.g., many tens of millions of years of divergence) then using a single reference genome to align their reads may end up throwing away much of your data since the organisms may have very divergent genomes. In that case the *denovo* assembly method can yield a lot more data for phylogenetic scale studies. \n",
    "\n",
    "Here we are continuing with a reference-based assembly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build loci from orthologous consensus reads\n",
    "data.run(\"6\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>[6] Question:</b> \n",
    "    What are advantages or disadvantages to using de novo versus reference-mapped RAD-seq loci? Answer in markdown below. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Apply filters and format output files\n",
    "This is typically the most important step of an ipyrad assembly. At step 7 you can apply different filters to your data and produce output files for downsteam analyes that include or exclude certain samples or loci that can make the data more suitable for different types of analyses. \n",
    "\n",
    "This is especially relevant to the issue of *missing data* in RAD-seq data sets. Many factors can contribute to why and how data is missing in RAD-seq data sets, and many papers have been written on the subject. Allelic dropout can lead to missing data when mutations occur in restriction recognition sites. Low sequencing coverage can lead to some regions not being sequenced. Uneven amplification of the library can lead to some fragments being sequenced to very high depth and others to very low depth. Whatever the cause, there is often missing data in RAD-seq data sets and the final step of an assembly should aim to minimize the missing data depending on your expected downstream analyses. \n",
    "\n",
    "For example, many studies have shown that missing data has little impact on phylogenetic inference methods, whereas it can hugely influence principle components analysis, or population structure analyses. We will explore missing data more in the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep loci that have data for N sample or more\n",
    "data.params.min_samples_locus = 10\n",
    "\n",
    "# run final assembly step\n",
    "data.run(\"7\", force=True, auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output files\n",
    "All of the files of this assembly are organized into the `project_dir` that we set as a parameter. Open a terminal from the jupyter dashboard page (select New then Terminal from that page) and navigate to this folder. Use the `less` command to look at the contents of each of the output files. Be sure to look at the stats output file labeled with the `_stat.txt` suffix. This file summarizes the stats output of the assembly. Because this is a simple assembly of simulated data the stats output is not too interesting though. We'll see another example from an empirical data set next time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the outfile paths are also accessible through the Assembly object\n",
    "data.outfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The .loci file\n",
    "This is a human readable format similar to a fasta format. It highlights the SNPs in the data and is easy to parse. It is useful to look at your results files to make sure that there are no apparent errors in your data or assembly. For example, a quick look will reveal if you mislabeled a taxon, or if one sample completely failed and produced no data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>[7] Question:</b> \n",
    "    Look at the output file produced by step 7 of ipyrad that has the .loci suffix in the directory shown above. How many SNPs are in the first locus?  Answer in Markdown below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The VCF file\n",
    "The VCF file (variant call format file) differs from the .loci file above in that it only shows the variant sites, and excludes the invariant sites. This is typical for VCF files. However, it contains additional information the other file formats lack in terms of the depths of coverage used during base calling. You can see in this file the numbers of A, T, C, and Gs that were present when a base was called homozygous or heterozygous in one or more samples at a variable site. This is useful because many downstream analysis tools can apply further filtering on the data in this file based on coverage and certainty in base calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The phylip file\n",
    "The phylip formatted file (.phy) contains the sequence data concatenated into one giant sequence alignment. This file can be used in some phylogenetic inference software. As an example, we can stick it into an analysis tool of ipyrad below to infer a phylogenetic tree and then plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyrad.analysis as ipa\n",
    "import toytree\n",
    "\n",
    "# infer a ML tree\n",
    "rax = ipa.raxml(data=data.outfiles.phy, N=10)\n",
    "rax.run(block=True, force=True)\n",
    "\n",
    "# plot the tree\n",
    "tre = toytree.tree(rax.trees.bipartitions)\n",
    "tre.root(wildcard=\"3\").draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>[8] Question:</b> \n",
    "    From the inferred tree above, if we assume each of the tips is a different species, which species do you think the reference genome is most closely related to?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylogenetics II\n",
    "\n",
    "You have now successfully assembled a RAD-seq comparative genomic data set and inferred a phylogeny from the resulting data. Over the next few notebooks to be assigned you will continue to apply RAD-seq methods to assemble a larger empirical data set and to apply phylogenetic and population genetic inference methods. For this we will focus on the Oak data set from the Eaton et al. 2015 paper that was assigned as a reading for this session. I understand that this paper is fairly complex and some students might struggle to follow all of the methods, especially if this topic is not your background. We will dissect the paper in class in detail in terms of the data assembly and the methods that are employed. For now if it feels over your head then please just at least skim the paper which should be sufficient to answer the questions below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>[9] Question:</b> \n",
    "    See Table 1 in the Eaton et al. paper which shows the number of RAD-seq loci that were included in de novo assembled data sets that were assembled with different parameter settings. The Allmin4 and Allmin20 assemblies differ greatly in the total number of loci, the number of informative sites, and the missing data. Why do you think \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>[10] Question:</b> \n",
    "    What does the term introgression mean? What do the authors argue are \"two important considerations\" to take when testing for introgression with genomic data? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
